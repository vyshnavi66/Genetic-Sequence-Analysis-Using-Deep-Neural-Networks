{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwdOFa9i-3eD"
      },
      "source": [
        "#Step 1: Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QsFV2Od8QPI",
        "outputId": "4c821bc5-b749-4893-f781-21dbcc13f06a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "btFCZiuY-VdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4af5f9-e116-41f9-eeae-88b34bdbeeb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dim1XSga--xC"
      },
      "source": [
        "#Step 2: Retreiving the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path='/content/drive/MyDrive/ML_PROJECT/test_set.csv'\n",
        "train_path='/content/drive/MyDrive/ML_PROJECT/training_set.csv'"
      ],
      "metadata": {
        "id": "qF2qHmtpBgCS"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "k_-APa-_-_E9"
      },
      "outputs": [],
      "source": [
        "training_set = pd.read_csv(train_path)\n",
        "test_set = pd.read_csv(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3 : Preprocessing"
      ],
      "metadata": {
        "id": "TVNW3dLL9oVV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "PodmWg82aUwJ"
      },
      "outputs": [],
      "source": [
        "def build_kmers(sequence, ksize=6):\n",
        "    return [sequence[i:i + ksize] for i in range(len(sequence) - ksize + 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "9eECGLz6q0jj"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(dataset):\n",
        "    kmer_list = []\n",
        "    labels = []\n",
        "    for index, row in dataset.iterrows():\n",
        "        seq = row['Sequence']\n",
        "        kmer = build_kmers(seq)\n",
        "        kmer_list.append(kmer)\n",
        "        if 'Type' in row:\n",
        "            labels.append(int(row['Type'][5]) - 1)\n",
        "    return kmer_list, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, train_labels = preprocess_data(training_set)\n",
        "X_test, _ = preprocess_data(test_set)"
      ],
      "metadata": {
        "id": "zDSedPq9p9oP"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_labels))\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbeEsXttVBNX",
        "outputId": "7dc45bd4-8aeb-4275-c808-1da820432013"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1320\n",
            "1320\n",
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(X_train, min_count=1, window=5, vector_size=100, workers=2)"
      ],
      "metadata": {
        "id": "sWRTjPBABZ5S"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_seq = X_train[0]\n",
        "sample_seq_kmer = sample_seq[0]\n",
        "print(f'sample kmer: {sample_seq_kmer}')\n",
        "print(f'Sample kmer w2v: {w2v_model.wv[sample_seq_kmer]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2xNPuFlB2Iq",
        "outputId": "c1fa33eb-f906-45b2-c346-97a374ba2bb2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample kmer: TACCAC\n",
            "Sample kmer w2v: [ 2.3776479   2.6899946  -0.33890477 -1.1045977  -4.639715    1.9600029\n",
            "  3.7117543  -2.9170442  -2.0395372  -1.5153934  -0.69263804  0.68987876\n",
            "  1.527658    0.2610632   1.7462404  -0.4663194  -0.18102738 -3.9838674\n",
            "  0.8829599  -0.19136968 -1.8968443  -0.09358894  2.1116765   4.033797\n",
            " -5.2704387  -2.6897018   3.5855355  -0.52097887  3.8898957  -0.57485557\n",
            "  3.7048821   0.63062936 -1.2361848  -1.8291693  -5.157497    0.9854158\n",
            "  1.2868885  -0.69918823 -2.1952283  -3.0263798  -2.1148303   1.0708619\n",
            " -2.9052565  -1.8970504   5.9707327  -0.6581267  -2.3918142  -1.910047\n",
            " -4.0771403  -0.8347278  -4.0109587  -1.831637   -3.4295733   1.6310542\n",
            " -2.1554422  -5.786013   -0.31428227 -2.3201156  -3.7162282   1.4674144\n",
            "  2.8870544  -5.9982514   4.0642004  -5.2227087  -1.5005418   5.4540305\n",
            "  2.6667504  -0.9510236   2.3661218  -0.9992615  -0.42011404  2.8512185\n",
            " -2.096042    2.8722057   0.29571018 -1.7142171   0.8305318   1.8911843\n",
            "  0.9015202  -0.04330012  1.1168213  -5.3952603   2.2790942  -0.01540641\n",
            "  2.0400057  -5.7525883   1.1240261   0.24585134  1.8023044   3.2013216\n",
            " -2.3650885  -3.5857432   1.7135158  -2.3823252  -1.5560837  -2.671839\n",
            "  0.17629638  0.9022066  -0.61870736  0.95471346]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seqs_embedding(w2v_model, seqs):\n",
        "  seqs_embedding = np.array([np.zeros(100)])\n",
        "  for seq in seqs:\n",
        "    vector = np.zeros(100)\n",
        "    for word in seq:\n",
        "      vector += w2v_model.wv[word]\n",
        "    number_of_word_in_seq = len(seq)\n",
        "    normalized_vector = vector / number_of_word_in_seq\n",
        "    seqs_embedding = np.append(seqs_embedding, [normalized_vector], axis=0)\n",
        "\n",
        "  return seqs_embedding[1: ]"
      ],
      "metadata": {
        "id": "5x_QtB-dDnSc"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embedding = create_seqs_embedding(w2v_model, X_train)"
      ],
      "metadata": {
        "id": "_u27MOHxEHwg"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_embedding = create_seqs_embedding(w2v_model, X_test)"
      ],
      "metadata": {
        "id": "oJpPnmjpEXRx"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = max(train_labels) + 1  # Find the number of unique classes\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Convert to one-hot encoding\n",
        "train_labels_modified = np.eye(num_classes)[train_labels]"
      ],
      "metadata": {
        "id": "YZH8z0iesa3z"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4 : Data Splitting\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XWgPA6jIuLUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embedding, X_val_embedding, Y_train_labels, Y_val_labels = train_test_split(\n",
        "    X_train_embedding, train_labels_modified, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "S6I8Dhu_sYao"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_embedding.shape)\n",
        "print(X_val_embedding.shape)\n",
        "print(Y_train_labels.shape)\n",
        "print(Y_val_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1nISDYJtG1u",
        "outputId": "c79e8fe7-382f-4e2d-e060-fcc59ead459c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1056, 100)\n",
            "(264, 100)\n",
            "(1056, 6)\n",
            "(264, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Step 5 : Building Model and validation Accuracy\n"
      ],
      "metadata": {
        "id": "-aWktpxLFPPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activate(x, activation_fn):\n",
        "    if activation_fn == 'sigmoid':\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    elif activation_fn == 'tanh':\n",
        "        return np.tanh(x)\n",
        "    elif activation_fn == 'relu':\n",
        "        return np.maximum(0, x)\n",
        "    else:\n",
        "        raise ValueError(\"Activation function not supported.\")\n",
        "\n",
        "def activate_derivative(x, activation_fn):\n",
        "    if activation_fn == 'sigmoid':\n",
        "        return x * (1 - x)\n",
        "    elif activation_fn == 'tanh':\n",
        "        return 1 - x ** 2\n",
        "    elif activation_fn == 'relu':\n",
        "        return np.where(x > 0, 1, 0)\n",
        "    else:\n",
        "        raise ValueError(\"Activation function not supported.\")"
      ],
      "metadata": {
        "id": "xthtkzjjvmRq"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Global variable to keep track of model parameters\n",
        "model_params = {}\n",
        "\n",
        "def initialize_network(X, Y, hidden_layer_sizes, activation_fn='relu', init_method='he'):\n",
        "    \"\"\"\n",
        "    Initialize network with specified hidden layer sizes.\n",
        "    hidden_layer_sizes: List of integers representing each hidden layer's size.\n",
        "    \"\"\"\n",
        "    input_size = X.shape[1]\n",
        "    output_size = Y.shape[1]\n",
        "\n",
        "    # Store activation function type\n",
        "    model_params['activation_fn'] = activation_fn\n",
        "    model_params['input_size'] = input_size\n",
        "    model_params['output_size'] = output_size\n",
        "    model_params['hidden_layer_sizes'] = hidden_layer_sizes\n",
        "\n",
        "    # Initialize weights and biases for each layer\n",
        "    layer_sizes = [input_size] + hidden_layer_sizes + [output_size]\n",
        "    for l in range(len(layer_sizes) - 1):\n",
        "        if init_method == 'he':\n",
        "            scale = np.sqrt(2 / layer_sizes[l])  # He initialization\n",
        "        else:\n",
        "            scale = np.sqrt(1 / layer_sizes[l])  # Default (Glorot/Xavier)\n",
        "\n",
        "        model_params[f'weights_{l + 1}'] = np.random.randn(layer_sizes[l], layer_sizes[l + 1]) * scale\n",
        "        model_params[f'bias_{l + 1}'] = np.zeros((1, layer_sizes[l + 1]))\n",
        "        model_params[f'weights_{l + 1}_adagrad'] = np.zeros_like(model_params[f'weights_{l + 1}'])\n",
        "        model_params[f'bias_{l + 1}_adagrad'] = np.zeros_like(model_params[f'bias_{l + 1}'])\n",
        "\n",
        "\n",
        "def forward_pass(X, verbose=False):\n",
        "    # Perform forward pass through all hidden layers and output layer\n",
        "    A = X\n",
        "    caches = {}\n",
        "    for l in range(1, len(model_params['hidden_layer_sizes']) + 2):\n",
        "        W = model_params[f'weights_{l}']\n",
        "        b = model_params[f'bias_{l}']\n",
        "        Z = np.dot(A, W) + b\n",
        "        A = activate(Z, model_params['activation_fn'])\n",
        "        caches[f'Z_{l}'] = Z\n",
        "        caches[f'A_{l}'] = A\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Layer {l}: output shape = {A.shape}\")\n",
        "\n",
        "    return caches\n",
        "\n",
        "def back_propagate(X, y, caches, learning_rate, l2_reg=0.01):\n",
        "    \"\"\"\n",
        "    Perform backpropagation through all layers, including L2 regularization.\n",
        "    \"\"\"\n",
        "    L = len(model_params['hidden_layer_sizes']) + 1  # Number of layers\n",
        "\n",
        "    # Output layer calculations\n",
        "    output = caches[f'A_{L}']\n",
        "    error_output = y - output\n",
        "    delta_output = error_output * activate_derivative(output, model_params['activation_fn'])\n",
        "\n",
        "    # Backpropagate through all hidden layers\n",
        "    deltas = {L: delta_output}\n",
        "    for l in range(L - 1, 0, -1):\n",
        "        Z = caches[f'Z_{l}']\n",
        "        A = caches[f'A_{l}']\n",
        "        W_next = model_params[f'weights_{l + 1}']\n",
        "        deltas[l] = (deltas[l + 1].dot(W_next.T)) * activate_derivative(A, model_params['activation_fn'])\n",
        "\n",
        "    # Update all layers with Adagrad and L2 regularization\n",
        "    for l in range(1, L + 1):\n",
        "        W = model_params[f'weights_{l}']\n",
        "        b = model_params[f'bias_{l}']\n",
        "        A_prev = X if l == 1 else caches[f'A_{l - 1}']\n",
        "\n",
        "        # Adagrad optimization update\n",
        "        model_params[f'weights_{l}_adagrad'] += np.square(A_prev.T.dot(deltas[l]))\n",
        "        model_params[f'bias_{l}_adagrad'] += np.square(np.sum(deltas[l], axis=0, keepdims=True))\n",
        "\n",
        "        weight_update = (A_prev.T.dot(deltas[l]) / (np.sqrt(model_params[f'weights_{l}_adagrad']) + 1e-8)) * learning_rate\n",
        "        bias_update = (np.sum(deltas[l], axis=0, keepdims=True) / (np.sqrt(model_params[f'bias_{l}_adagrad']) + 1e-8)) * learning_rate\n",
        "\n",
        "        model_params[f'weights_{l}'] += weight_update - learning_rate * l2_reg * W\n",
        "        model_params[f'bias_{l}'] += bias_update\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1OkjVR_gGZk4"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X_train, y_train, epochs, learning_rate, l2_reg=0.01):\n",
        "    for epoch in range(epochs):\n",
        "        caches = forward_pass(X_train)\n",
        "        back_propagate(X_train, y_train, caches, learning_rate, l2_reg=l2_reg)\n",
        "    y_train_normalized = (y_train - y_train.mean()) / y_train.std()\n",
        "    final_output = caches[f'A_{len(model_params[\"hidden_layer_sizes\"]) + 1}']\n",
        "    print(f\"Train Error MSE: %.5f\" % mse(y_train_normalized, final_output))\n",
        "    print(f\"Training Accuracy: {(np.round(final_output) == y_train).mean()}\")\n",
        "\n",
        "def mse(y1, y2):\n",
        "    return np.mean((y1 - y2) ** 2)"
      ],
      "metadata": {
        "id": "uMFvFsyrwNyU"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initialize_network(X_train_embedding, Y_train_labels, hidden_layer_sizes=[64, 64, 32,32], activation_fn='relu', init_method='he')\n",
        "train(X_train_embedding, Y_train_labels, epochs=1000, learning_rate=0.001, l2_reg=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BgagJmkwQFW",
        "outputId": "58a139ce-b9e3-421e-a6dc-10b65e52c3ca"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error MSE: 0.61515\n",
            "Training Accuracy: 0.944760101010101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(X, y_true):\n",
        "    caches = forward_pass(X)\n",
        "    final_output = caches[f'A_{len(model_params[\"hidden_layer_sizes\"]) + 1}']\n",
        "\n",
        "    # For classification: Predict classes\n",
        "    predicted_classes = np.argmax(final_output, axis=1)\n",
        "    true_classes = np.argmax(y_true, axis=1)\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = np.mean(predicted_classes == true_classes)\n",
        "\n",
        "    # Compute MSE based on class indices for educational purposes (not common in practice for classification)\n",
        "    mse_value = np.mean((predicted_classes - true_classes) ** 2)\n",
        "\n",
        "    return accuracy, mse_value\n"
      ],
      "metadata": {
        "id": "m9iRB_PkyjZ-"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy, mse_value = evaluate_model(X_val_embedding, Y_val_labels)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"TEST ERROR MSE: {mse_value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97whSrvNyqY5",
        "outputId": "20f497b5-f1e9-43d1-a2e4-e6773ef5ae00"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8295\n",
            "TEST ERROR MSE: 0.1818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Step 6 : Testing with new Data"
      ],
      "metadata": {
        "id": "g0sYTzF7tkVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(X_test):\n",
        "    caches = forward_pass(X_test)\n",
        "    final_output = caches[f'A_{len(model_params[\"hidden_layer_sizes\"]) + 1}']\n",
        "    predicted_classes = np.argmax(final_output, axis=1)\n",
        "    print(f\"Predicted Classes: {predicted_classes}\")"
      ],
      "metadata": {
        "id": "h_jzmVTGvd7o"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(X_test_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7IwHiU9tjUF",
        "outputId": "d452f1b7-255a-4d98-c27c-bd0d37058f0d"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Classes: [4 4 2 0 5 0 5 2 3 0 3 2 0 3 3 2 5 2 2 2 3 0 4 5 0 4 2 2 2 2 0 2 5 0 5 0 2\n",
            " 4 4 5 4 3 4 4 2 5 3 4 0 0 3 2 3 2 2 5 2 5 4 2 0 2 2 2 2 5 3 4 5 5 5 2 0 5\n",
            " 0 0 3 5 5 0 4 3 0 0 2 4 5 3 2 4 2 0 0 5 4 2 4 0 3 0 2 2 0 0 2 3 2 2 2 2 2\n",
            " 0 3 0 3 3 2 2 2 3 5 0 5 3 4 2 5 0 2 2 2 5 4 0 0 2 0 0 2 2 4 0 5 3 0 0 0 2\n",
            " 0 3 5 5 0 5 2 4 4 2 5 2 0 0 3 3 2 2 4 3 0 0 0 2 5 0 2 0 5 3 4 5 4 5 4 4 5\n",
            " 2 2 2 5 3 5 2 2 5 5 5 0 0 4 3 0 2 2 0 0 0 4 2 0 0 0 0 0 2 2 5 2 2 3 4 5 3\n",
            " 0 3 2 3 5 4 3 5 4 4 5 5 3 4 2 5 5 2 0 0 3 3 3 4 0 0 5 0 5 2 0 0 2 0 2 5 5\n",
            " 4 2 2 5 0 2 2 0 0 4 3 0 2 0 0 0 0 2 2 2 5 0 5 3 0 2 3 2 2 3 2 0 2 5 5 0 0\n",
            " 5 0 0 5 5 2 3 0 5 4 5 2 3 0 3 2 0 5 4 4 0 2 4 3 4 0 2 2 3 0 0 0 0 0 2 4 0\n",
            " 2 2 3 0 4 0 4 3 2 0 2 2 0 4 3 3 2 0 4 3 0 0 0 0 0 0 2 4 5 0 5 2 0 5 3 0 0\n",
            " 0 0 2 4 5 2 0 0 3 0 0 5 2 5 2 3 0 5 5 2 2 0 0 5 2 0 2 0 4 0]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}